{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7866699,"sourceType":"datasetVersion","datasetId":4615357}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install opacus\n!pip install datasets==2.15\n!pip install peft","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom peft import PeftModel, PeftConfig, LoraConfig, TaskType, get_peft_model\nimport torch\nfrom torch.utils.data import DataLoader\nimport pandas as pd\nimport numpy as np\nimport os\nfrom opacus import PrivacyEngine\nfrom tqdm import tqdm\nfrom datasets import load_from_disk","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_path = \"/kaggle/input/privacy-datasets2/Privacy_datasets/mnli\"\n\ntokenized_datasets = load_from_disk(dataset_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(tokenized_datasets[\"train\"], batch_size=1024, shuffle=True)\neval_dataloader = DataLoader(tokenized_datasets[\"validation_matched\"], batch_size=1024)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lora_config = LoraConfig(\n    task_type=TaskType.SEQ_CLS, r=4, lora_alpha=16, lora_dropout=0.1)\n\nbase_model = BertForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\",num_labels=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_peft_model(base_model, lora_config)\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.005, eps=1e-8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.print_trainable_parameters()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.train()\ntarget_epsilon = 3\ntarget_delta = 1.0 / len(tokenized_datasets[\"train\"])\nepochs = 30\nmax_grad_norm = 0.7\n\nprivacy_engine = PrivacyEngine()\nmodel, optimizer, train_dataloader = privacy_engine.make_private_with_epsilon(\n    module=model,\n    optimizer=optimizer,\n    data_loader=train_dataloader,\n    target_epsilon=target_epsilon,\n    target_delta=target_delta,\n    epochs=epochs,\n    max_grad_norm=max_grad_norm\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model):    \n    model.eval()\n\n    total_loss = 0\n    correct_predictions = 0\n    total_predictions = 0\n\n    with torch.no_grad():\n        for batch in eval_dataloader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            token_type_ids = batch['token_type_ids'].to(device)\n\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels, token_type_ids=token_type_ids)\n            loss = outputs.loss\n            total_loss += loss.item()\n            logits = outputs.logits\n            preds = torch.argmax(logits, dim=1)\n            correct_predictions += (preds == labels).sum().item()\n            total_predictions += labels.size(0)\n\n    avg_loss = total_loss / len(eval_dataloader)\n    accuracy = correct_predictions / total_predictions\n    model.train()\n    return avg_loss, accuracy\n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from opacus.utils.batch_memory_manager import BatchMemoryManager\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nfor epoch in range(1, epochs+1):\n    losses = []\n\n    with BatchMemoryManager(\n        data_loader=train_dataloader, \n        max_physical_batch_size=1024, \n        optimizer=optimizer\n    ) as memory_safe_data_loader:\n        for step, batch in enumerate(tqdm(memory_safe_data_loader)):\n            optimizer.zero_grad()\n\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            token_type_ids = batch['token_type_ids'].to(device)\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            loss.backward()\n            losses.append(loss.item())\n\n            optimizer.step()\n\n    train_loss = np.mean(losses)\n    eps = privacy_engine.get_epsilon(target_delta) if privacy_engine else None\n\n    eval_loss, eval_accuracy = evaluate(model)\n\n    print(\n        f\"Epoch: {epoch} | \"\n        f\"Train loss: {train_loss:.3f} | \"\n        f\"Eval loss: {eval_loss:.3f} | \"\n        f\"Eval accuracy: {eval_accuracy:.3f} | \"\n        f\"É›: {eps:.2f}\" if eps is not None else \"\"\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n\nfor epoch in range(1, epochs+1):\n    model.train()\n    total_train_loss = 0\n    \n    for batch in tqdm(train_dataloader):\n        optimizer.zero_grad()\n        \n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        token_type_ids = batch['token_type_ids'].to(device)\n        \n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels, token_type_ids=token_type_ids)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        \n        total_train_loss += loss.item()\n    \n    train_loss = total_train_loss / len(train_dataloader)\n    \n    model.eval()\n    with torch.no_grad():\n        eval_loss, eval_accuracy = evaluate(model)\n    \n    print(\n        f\"Epoch: {epoch} | \"\n        f\"Train loss: {train_loss:.3f} | \"\n        f\"Eval loss: {eval_loss:.3f} | \"\n        f\"Eval accuracy: {eval_accuracy:.3f} | \"\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(model, test_dataloader):\n    model.eval()\n\n    total_loss = 0\n    correct_predictions = 0\n    total_predictions = 0\n\n    with torch.no_grad():\n        for batch in test_dataloader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            token_type_ids = batch['token_type_ids'].to(device)\n            \n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels, token_type_ids=token_type_ids)\n            loss = outputs.loss\n            total_loss += loss.item()\n            logits = outputs.logits\n            preds = torch.argmax(logits, dim=1)\n            correct_predictions += (preds == labels).sum().item()\n            total_predictions += labels.size(0)\n\n    avg_loss = total_loss / len(test_dataloader)\n    accuracy = correct_predictions / total_predictions\n\n    return avg_loss, accuracy","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = test(model, test_dataloader)\n\nprint(f\"Accuracy: {test_accuracy:.3f}\")","metadata":{},"execution_count":null,"outputs":[]}]}